import os
import sys
from bs4 import BeautifulSoup
import scraper as scraper
from parsers import get_parser # å¼•å…¥è§£æå™¨

def test_single_url(url, journal_name):
    print(f"\nğŸ” Testing for Journal: {journal_name}...")
    print(f"   URL: {url}")
    
    # 1. æ¨¡æ‹Ÿç½‘ç»œè¯·æ±‚
    # soup = scraper.get_soup(url) # å¦‚æœä½ æƒ³è·‘çœŸå®ç½‘ç»œ
    # æˆ–è€…è¯»å–æœ¬åœ°æ–‡ä»¶ï¼š

    with open(url, 'r', encoding='utf-8') as f:
        soup = BeautifulSoup(f.read(), 'html.parser')

    # 2. è·å–å¯¹åº”çš„è§£æå™¨
    parser_func = get_parser(journal_name)
    
    # 3. è¿è¡Œè§£æ
    details = parser_func(soup)
    
    print("\n   ------ PARSED RESULT ------")
    print(f"   ğŸ—“ï¸  Deadline:    {details['deadline']}")
    print(f"   ğŸ‘¥ Editors:     {details['editors'][:100]}...") 
    print(f"   ğŸ“ Description: {details['description'][:100]}...")

if __name__ == "__main__":
    # æ­¤æ—¶éœ€è¦ä½ åœ¨æ ¹ç›®å½•ä¸‹æœ‰ rse.html å’Œ cities.html
    test_single_url("test_data/cities.html", "Cities")
    test_single_url("test_data/rse.html", "Remote Sensing of Environment")
    test_single_url("test_data/bae.html", "Building and Environment")
    test_single_url("test_data/ceus.html", "Computers, Environment and Urban Systems")